\section{Motivação e Contexto~\label{sec:Motivação-e-Contexto}}

O avanço das tecnologias de comunicação, gerando uma abundância maior de
informações bastante notória principalmente com a popularização da internet,
traz à área de jornalismo mudanças em seu modo de produção. Com o pauteiro
guiando a linha editorial buscando fatos, tendências e fenômenos, é papel do
jornalista narrar uma história --- ou seja, construir uma matéria ---  que
corresponda a essas pautas e para isso buscar formas (entrevistas com os
envolvidos na pauta, documentos, etc.) de responder as 6 perguntas básicas do
jornalismo: Quem, O quê, Quando, Onde, Por Quê, e
Como~\cite{ijnet:examinando-perguntas-jornalismo}. Quando se trata de
Jornalismo de Dados\footnote{Também chamado em inglês de \textit{Data-Driven
Journalism}.}, esse volume maior de informações fornece a determinados
jornalistas acesso a bases de dados que nelas essas perguntas já estão
respondidas, mas não há nem uma \textbf{sintetização conclusiva} desses dados e
tampouco uma \textbf{humanização}\footnote{``Humanização de dados'', no
jornalismo, é apresentá-los de forma que o público deixe de vê-los como apenas
números e passem a perceber que eles se referem a pessoas, a seres
humanos.}~\cite{ijnet:como-humanizar-dados}. É, por exemplo, o contraste entre
tabelas contendo informações sobre condenações, localidades e renda familiar, e
uma matéria apontando que o sistema judiciário é mais severo quando a
condenação se aplica a pessoas que moram em locais da
periferia~\cite{news:sentenças-mais-severas-para-periferia}. O trabalho do
jornalista de dados é então, em resumo, tratar de humanizar e apresentar esses
dados ao público.

Porém ainda que se haja abundância de informação, isso não significa que ela
esteja acessível de forma conveniente para jornalistas. Uma base de dados
expressa em uma planilha, agregada em um CSV ou seguindo alguma implementação
de SQL é manipulável por \textit{softwares} e bibliotecas que muitas vezes são
Software-Livre (e portanto de livre uso~\cite{def:free-software}) e permitem a
reorganização, filtragem, geração de gráficos estatísticos e outras tarefas
conforme a necessidade de quem se propõe a escrever uma matéria jornalística.
Já casos como os Tribunais Regionais de Justiça (TJs, para simplificação)
brasileiros não fornecem seus dados (nesse caso, dados processuais) em nenhuma
dessas formas, em vez disso o que há são resultados parciais (com relação ao
todo dos processos registrados no portal do TJ) a partir de buscas pontuais
como nome das partes, sentença, informações de advogados envolvidos, etc, ou
seja, a informação está esparsa e tentar juntá-la manualmente pode ser
humanamente impossível já que há milhões de processos por ano em apenas um TJ
como o do Rio de Janeiro~\cite{tjrj}. Há uma demanda --- elencada em conversa
com profissionais da área de Jornalismo Investigativo --- pela sintetização
desses dados e por consultas mais abrangentes, como busca pelo assunto do
processo, assim um jornalista que atue com processos trabalhistas poderia
analisar apenas os que dizem respeito essa área.

Para casos como esse em que um portal de informações não as disponibiliza de
forma conveniente, uma forma de contornar essa deficiência é através de
raspagem de dados, ou seja, o uso de ferramentas de software que façam a
varredura de páginas da internet buscando e reorganizando dados de interesse de
forma que possam ser posteriormente processados. O uso dessas ferramentas,
chamadas de ``extratores'', para tais finalidades dentro do jornalismo de
dados, aliado a outras práticas, caracteriza o ``jornalismo investigativo''.
Para os TJs, porém, não há --- ao menos de acesso fácil e público --- esse tipo
de ferramenta, dificultando o trabalho de jornalistas investigativos na
obtenção e análise de processos.
